public class WebCrawler {

    //BFS; Linked list since we don't know nodes ahead of time.
    //for each of the links present in source file, make a thing that logs each of the pages that you get from
    //clicking on that link. Proceed exponentially, branching out as a tree until the target page is found. Once that
    //target is found, trace backwards to source and output length of path that is shortest. Node should go under first
    //link to discover it because it is guaranteed to be the shortest path.




//pages = nodes; links = edges

    //six degrees of wikipedia website as framework inspo

    //main function that takes in user input of targer and source via scanner

}